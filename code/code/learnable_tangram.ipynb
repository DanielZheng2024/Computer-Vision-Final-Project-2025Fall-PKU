{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941cd80f",
   "metadata": {},
   "source": [
    "# 支持Learnable Layout的Tangram, 使用了Image Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade -r requirements.txt\n",
    "%pip install rp --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa2cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import source.stable_diffusion as sd\n",
    "from source.learnable_textures import LearnableImageFourier\n",
    "from source.stable_diffusion_labels import NegativeLabel\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 环境配置：使用镜像源加速模型下载\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "# 初始化设备与模型\n",
    "gpu = rp.select_torch_device()\n",
    "model_name = \"runwayml/stable-diffusion-v1-5\"\n",
    "s = sd.StableDiffusion(gpu, model_name)\n",
    "device = s.device\n",
    "\n",
    "print(f\"Device: {device} | Model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xy_grid(h, w, device):\n",
    "    ys = torch.linspace(-1, 1, h, device=device)\n",
    "    xs = torch.linspace(-1, 1, w, device=device)\n",
    "    y, x = torch.meshgrid(ys, xs, indexing='ij')\n",
    "    return x, y\n",
    "\n",
    "def triangle_mask(x, y, p0, p1, p2, sharpness=80.0):\n",
    "    pts = [p0, p1, p2]\n",
    "    m = torch.ones_like(x)\n",
    "    for i in range(3):\n",
    "        pi, pj, pk = pts[i], pts[(i+1)%3], pts[(i+2)%3]\n",
    "        ex, ey = (pj[0]-pi[0]), (pj[1]-pi[1])\n",
    "        a, b, c = -ey, ex, -( (-ey)*pi[0] + ex*pi[1] )\n",
    "        if a*pk[0] + b*pk[1] + c < 0: a, b, c = -a, -b, -c\n",
    "        m = m * torch.sigmoid(sharpness * (a*x + b*y + c))\n",
    "    return m\n",
    "\n",
    "def square_mask(x, y, cx=0.0, cy=0.0, s=0.25, sharpness=80.0):\n",
    "    return (torch.sigmoid(sharpness*(x-(cx-s))) * torch.sigmoid(sharpness*((cx+s)-x)) *\n",
    "            torch.sigmoid(sharpness*(y-(cy-s))) * torch.sigmoid(sharpness*((cy+s)-y)))\n",
    "\n",
    "def parallelogram_mask(x, y, cx=0.0, cy=0.0, w=0.55, h=0.22, shear=0.6, sharpness=80.0):\n",
    "    u = x - shear*y\n",
    "    return (torch.sigmoid(sharpness*(u-(cx-w/2))) * torch.sigmoid(sharpness*((cx+w/2)-u)) *\n",
    "            torch.sigmoid(sharpness*(y-(cy-h/2))) * torch.sigmoid(sharpness*((cy+h/2)-y)))\n",
    "\n",
    "# 初始化 7 个碎片\n",
    "SIZE = 512\n",
    "x_grid, y_grid = make_xy_grid(SIZE, SIZE, device)\n",
    "T1 = triangle_mask(x_grid, y_grid, (-0.95, -0.95), (-0.15, -0.95), (-0.95, -0.15))\n",
    "T2 = triangle_mask(x_grid, y_grid, ( 0.15, -0.95), ( 0.95, -0.95), ( 0.95, -0.15))\n",
    "T3 = triangle_mask(x_grid, y_grid, (-0.95,  0.15), (-0.15,  0.15), (-0.95,  0.95))\n",
    "T4 = triangle_mask(x_grid, y_grid, ( 0.15,  0.15), ( 0.55,  0.15), ( 0.15,  0.55))\n",
    "T5 = triangle_mask(x_grid, y_grid, ( 0.60,  0.20), ( 0.95,  0.20), ( 0.95,  0.55))\n",
    "SQ = square_mask(x_grid, y_grid, cx=0.55, cy=0.75, s=0.18)\n",
    "PA = parallelogram_mask(x_grid, y_grid, cx=0.10, cy=0.75, w=0.55, h=0.22, shear=0.6)\n",
    "\n",
    "piece_masks = [T1, T2, T3, T4, T5, SQ, PA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTangramLayout(nn.Module):\n",
    "    def __init__(self, device, num_layouts=2, initial_configs=None):\n",
    "        super().__init__()\n",
    "        # 形状为 [N, 7, 4]，N 是布局数量\n",
    "        self.params = nn.Parameter(torch.zeros((num_layouts, 7, 4), device=device))\n",
    "        \n",
    "        if initial_configs:\n",
    "            # initial_configs 应该是一个包含 N 个 list 的 list\n",
    "            with torch.no_grad():\n",
    "                for n in range(num_layouts):\n",
    "                    for i, cfg in enumerate(initial_configs[n]):\n",
    "                        self.params[n, i, 0] = cfg.get('tx', 0)\n",
    "                        self.params[n, i, 1] = cfg.get('ty', 0)\n",
    "                        self.params[n, i, 2] = math.radians(cfg.get('rot_deg', 0))\n",
    "                        self.params[n, i, 3] = math.log(cfg.get('scale', 1.0))\n",
    "\n",
    "    def forward(self, prime_img, piece_masks, size, layout_idx=0):\n",
    "        out = torch.zeros_like(prime_img)\n",
    "        transformed_masks = []\n",
    "        \n",
    "        current_params = self.params[layout_idx]\n",
    "        \n",
    "        for i in range(len(piece_masks)):\n",
    "            p = current_params[i]\n",
    "            tx, ty = torch.tanh(p[0]), torch.tanh(p[1])\n",
    "            rot_rad = p[2]\n",
    "            scale = torch.exp(p[3])\n",
    "            \n",
    "            # 仿射变换矩阵\n",
    "            cos_t, sin_t = torch.cos(rot_rad), torch.sin(rot_rad)\n",
    "            theta = torch.stack([\n",
    "                torch.stack([scale * cos_t, -scale * sin_t, tx]),\n",
    "                torch.stack([scale * sin_t,  scale * cos_t, ty])\n",
    "            ]).unsqueeze(0)\n",
    "            \n",
    "            p_img = prime_img * piece_masks[i].unsqueeze(0)\n",
    "            grid = F.affine_grid(theta, size=(1, 3, size, size), align_corners=False)\n",
    "            warped = F.grid_sample(p_img.unsqueeze(0), grid, mode='bilinear', \n",
    "                                   padding_mode='zeros', align_corners=False).squeeze(0)\n",
    "            out = out + warped\n",
    "            \n",
    "            m_warped = F.grid_sample(piece_masks[i].view(1,1,size,size), grid, \n",
    "                                     mode='bilinear', padding_mode='zeros', align_corners=False)\n",
    "            transformed_masks.append(m_warped)\n",
    "            \n",
    "        return out, transformed_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARR_A = [dict(tx=-0.2, ty=-0.2, rot_deg=0, scale=1.0), dict(tx=0.2, ty=-0.2, rot_deg=90, scale=1.0), dict(tx=-0.2, ty=0.2, rot_deg=-90, scale=0.9), dict(tx=0.15, ty=0.15, rot_deg=0, scale=0.9), dict(tx=0.35, ty=0.35, rot_deg=180, scale=0.85), dict(tx=0.0, ty=0.35, rot_deg=45, scale=0.9), dict(tx=-0.05, ty=0.05, rot_deg=0, scale=0.95)]\n",
    "ARR_B = [dict(tx=-0.35, ty=-0.1, rot_deg=45, scale=1.0), dict(tx=0.1, ty=-0.35, rot_deg=135, scale=1.0), dict(tx=-0.05, ty=0.05, rot_deg=45, scale=0.95), dict(tx=0.25, ty=0.15, rot_deg=45, scale=0.9), dict(tx=0.35, ty=0.35, rot_deg=45, scale=0.85), dict(tx=0.05, ty=0.3, rot_deg=0, scale=0.95), dict(tx=-0.2, ty=0.25, rot_deg=45, scale=0.95, flip_x=True)]\n",
    "\n",
    "all_initial_configs = [ARR_A, ARR_B]\n",
    "\n",
    "def load_ref_image(path, device):\n",
    "    img = rp.load_image(path)\n",
    "    img = rp.resize_image(img, (512, 512)) # 必须缩放到 512 匹配 SD\n",
    "    img_t = torch.from_numpy(img).permute(2, 0, 1).float().unsqueeze(0) / 255.0\n",
    "    return img_t.to(device)\n",
    "    \n",
    "ref_images = [\n",
    "    load_ref_image(\"3.jpg\", device),   # 对应 Prompt A\n",
    "    load_ref_image(\"2.jpg\", device)  # 对应 Prompt B\n",
    "]\n",
    "ref_image_coefs = [0.3, 0.2]\n",
    "\n",
    "\n",
    "target_prompts = [\n",
    "    \"\",\n",
    "    \"a blue robot, cinematic lighting, high quality\"\n",
    "]\n",
    "labels = [NegativeLabel(p, \"low quality, blurry\") for p in target_prompts]\n",
    "\n",
    "prime = LearnableImageFourier(height=SIZE, width=SIZE).to(device)\n",
    "multi_layout = MultiTangramLayout(device, num_layouts=2, initial_configs=all_initial_configs).to(device)\n",
    "\n",
    "optim = torch.optim.Adam([\n",
    "    {'params': prime.parameters(), 'lr': 1e-3},\n",
    "    {'params': multi_layout.parameters(), 'lr': 5e-4} \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0df8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 参数配置 ---\n",
    "NUM_ITER = 4000\n",
    "DISPLAY_INTERVAL = 100\n",
    "LAMBDA_OVERLAP = 25.0  \n",
    "LAMBDA_COMPACT = 0.05\n",
    "\n",
    "television = rp.JupyterDisplayChannel(); television.display()\n",
    "display_eta = rp.eta(NUM_ITER, title='Multi-Tangram Training')\n",
    "ims = []\n",
    "\n",
    "def get_constraints_multi(masks, idx, model):\n",
    "    all_masks = torch.cat(masks, dim=1)\n",
    "    mask_sum = all_masks.sum(dim=1)\n",
    "    overlap_loss = torch.mean(F.relu(mask_sum - 1.1)**2)\n",
    "    compact_loss = torch.mean(model.params[idx, :, :2]**2)\n",
    "    return overlap_loss, compact_loss\n",
    "\n",
    "try:\n",
    "    for iter_num in range(NUM_ITER):\n",
    "        display_eta(iter_num)\n",
    "        \n",
    "        total_geom_loss = 0\n",
    "        \n",
    "        for idx in range(len(labels)):\n",
    "            \n",
    "            img, masks = multi_layout(prime(), piece_masks, SIZE, layout_idx=idx)\n",
    "            \n",
    "            s.train_step(\n",
    "                text_embeddings = labels[idx].embedding,\n",
    "                pred_rgb = img[None],\n",
    "                guidance_scale = 100,\n",
    "                noise_coef = 0.1,\n",
    "                ref_image = ref_images[idx],   \n",
    "                ref_image_coef = ref_image_coefs[idx]\n",
    "            )\n",
    "            \n",
    "            # 计算该布局下的几何约束 \n",
    "            overlap_l, compact_l = get_constraints_multi(masks, idx, multi_layout)\n",
    "            total_geom_loss += (overlap_l * LAMBDA_OVERLAP) + (compact_l * LAMBDA_COMPACT)\n",
    "        \n",
    "        total_geom_loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        if not iter_num % DISPLAY_INTERVAL:\n",
    "            with torch.no_grad():\n",
    "                current_views = []\n",
    "                for idx in range(len(labels)):\n",
    "                    v_img, _ = multi_layout(prime(), piece_masks, SIZE, layout_idx=idx)\n",
    "                    current_views.append(rp.as_numpy_image(v_img.clamp(0, 1)))\n",
    "                \n",
    "\n",
    "                base_tex = rp.as_numpy_image(prime().clamp(0, 1))\n",
    "                \n",
    "                combined = rp.tiled_images(current_views + [base_tex], length=len(labels)+1)\n",
    "                \n",
    "                television.update(combined)\n",
    "                ims.append(combined)\n",
    "                rp.display_image(combined)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted at', iter_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = multi_layout.params \n",
    "for layout_idx in range(2):\n",
    "    current_layout = all_params[layout_idx] \n",
    "\n",
    "    print(f\"Learned Tangram Layout {layout_idx} (tx, ty, rot_deg, scale):\")\n",
    "    for i in range(current_layout.size(0)):\n",
    "        p = current_layout[i].flatten()\n",
    "    \n",
    "        print(f\"Piece {i}: tx={torch.tanh(p[0]).item():.2f}, \"\n",
    "              f\"ty={torch.tanh(p[1]).item():.2f}, \"\n",
    "              f\"rot={math.degrees(p[2].item()):.1f}°, \"\n",
    "              f\"scale={torch.exp(p[3]).item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def save_run(name):\n",
    "    folder = f\"untracked/learnabletangram_runs/{name}\"\n",
    "    if rp.path_exists(folder):\n",
    "        folder += f\"_{int(time.time())}\"\n",
    "    rp.make_directory(folder)\n",
    "    ims_names = [f\"ims_{i:04d}.png\" for i in range(len(ims))]\n",
    "    with rp.SetCurrentDirectoryTemporarily(folder):\n",
    "        rp.save_images(ims, ims_names, show_progress=True)\n",
    "    print('Saved timelapse to:', folder)\n",
    "\n",
    "save_run('tangram_a-b')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
