{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3288798",
   "metadata": {},
   "source": [
    "# Anamorphic Illusion (Perspective Projection)\n",
    "This notebook implements an Anamorphic Illusion generation pipeline. \n",
    "The goal is to create an image that looks like one thing from a top-down view (View A), but reveals a different 3D object when viewed from a specific grazing angle (View B).\n",
    "Gaining the idea from Hitchhock's famous \"Vertigo\" effect, we use perspective warping to simulate the change in viewpoint.\n",
    "\n",
    "### Concept\n",
    "- **View A (Top-down)**: The original image, printed on a flat surface. Prompt: \"A distinct texture of wood\".(can be changed to any texture)\n",
    "- **View B (Perspective)**: The image seen from a low angle, simulated by a perspective transform. Prompt: \"A standing 3D coca-cola can\".(can be changed to any 3D object)\n",
    "\n",
    "The optimization process modifies the pixels of View A so that both views satisfy their respective text prompts.\n",
    "\n",
    "### Run Instructions\n",
    "1.  Use kaggle, choose GPU P100 as accelerator.\n",
    "2.  Run the first cell block.\n",
    "3.  Restart the cells.\n",
    "4.  Run the rest of the cells sequentially.\n",
    "5.  You can change the prompts for the 2 views in the third cell block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5eac5b-9d38-44c8-82e7-0ed73e4298ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T13:38:19.547641Z",
     "iopub.status.busy": "2026-01-17T13:38:19.546901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title 1. Setup Environment \n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# install a numpy version that is compatible with other dependencies\n",
    "!pip install \"numpy==1.26.4\" \n",
    "\n",
    "# force reinstallation and clear up any existing directory\n",
    "repo_name = \"Diffusion-Illusions\"\n",
    "if os.path.exists(repo_name):\n",
    "    print(f\"Removing existing {repo_name} directory...\")\n",
    "    shutil.rmtree(repo_name)\n",
    "\n",
    "print(f\"Cloning repository into {repo_name}...\")\n",
    "# clone to child file\n",
    "!git clone -b master https://github.com/RyannDaGreat/Diffusion-Illusions {repo_name}\n",
    "\n",
    "# change into the repo directory\n",
    "os.chdir(repo_name)\n",
    "print(f\"Current working directory changed to: {os.getcwd()}\")\n",
    "with open(\"requirements.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    for line in lines:\n",
    "        if \"matplotlib\" in line:\n",
    "            f.write(\"matplotlib\\n\") \n",
    "        elif \"numpy\" in line:\n",
    "            continue # skip numpy for it's already installed\n",
    "        else:\n",
    "            f.write(line)\n",
    "\n",
    "# install the rest\n",
    "!pip install -r requirements.txt\n",
    "!pip install rp --upgrade\n",
    "\n",
    "print(\"\\n Installation complete!\")\n",
    "print(\"⚠️ Important: Please now click 'Runtime' -> 'Restart session' in the menu!\")\n",
    "print(\"⚠️ After restarting, you do not need to run this cell again. Just run the subsequent code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a47a6b",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title Load Stable Diffusion and Libraries\n",
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F# @title Load Stable Diffusion and Libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# put the Diffusion-Illusions folder into the Python path to avoid strange errs.\n",
    "if os.path.exists(\"Diffusion-Illusions\"):\n",
    "    sys.path.append(os.path.abspath(\"Diffusion-Illusions\"))\n",
    "    print(\"已将 Diffusion-Illusions 加入 Python 路径\")\n",
    "\n",
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import source.stable_diffusion as sd\n",
    "from easydict import EasyDict\n",
    "from source.learnable_textures import LearnableImageFourier\n",
    "from source.stable_diffusion_labels import NegativeLabel\n",
    "from itertools import chain\n",
    "import time\n",
    "\n",
    "# Initialize SD Model\n",
    "if 's' not in dir():\n",
    "    model_name=\"CompVis/stable-diffusion-v1-4\"\n",
    "    gpu='cuda:0'\n",
    "    s=sd.StableDiffusion(gpu,model_name)\n",
    "    device=s.device\n",
    "\n",
    "print(\"Model Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Perspective Warp Function\n",
    "\n",
    "def get_perspective_warp_grid(height, width, device, top_scale=1.0, bot_scale=0.35):\n",
    "    \"\"\"\n",
    "    Generates a sampling grid for perspective transformation (Anamorphic Illusion).\n",
    "    Args:\n",
    "        top_scale: How much wider the sampling region is at the top (Far end). > 1.0 means we sample a wider area.\n",
    "        bot_scale: How much wider/narrower the sampling region is at the bottom (Near end).\n",
    "    \"\"\"\n",
    "    \n",
    "    # the 4 corners of the Output. (Mapping Needs)\n",
    "    dst_points = np.float32([\n",
    "        [-1, -1], [1, -1], [1, 1], [-1, 1]\n",
    "    ])\n",
    "    # the 4 corners of the Input.\n",
    "    src_points = np.float32([\n",
    "        [-top_scale, -1], [top_scale, -1], [bot_scale, 1], [-bot_scale, 1]\n",
    "    ])\n",
    "    \n",
    "    # use cv2 functions to compute homography matrix\n",
    "    M = cv2.getPerspectiveTransform(dst_points, src_points)\n",
    "    M_tensor = torch.from_numpy(M).to(device).float()\n",
    "    \n",
    "    # Create Grid for Output Image\n",
    "    y_range = torch.linspace(-1, 1, height, device=device)\n",
    "    x_range = torch.linspace(-1, 1, width, device=device)\n",
    "    uy, ux = torch.meshgrid(y_range, x_range, indexing='ij')\n",
    "    \n",
    "    ones = torch.ones_like(ux)\n",
    "    grid_homogeneous = torch.stack((ux, uy, ones), dim=-1) # to homogeneous coords\n",
    "    # Apply transformation\n",
    "    grid_transformed = torch.matmul(grid_homogeneous, M_tensor.T)\n",
    "    \n",
    "    # Convert back from homogeneous coordinates\n",
    "    grid_x = grid_transformed[..., 0] / grid_transformed[..., 2]\n",
    "    grid_y = grid_transformed[..., 1] / grid_transformed[..., 2]\n",
    "    \n",
    "    grid = torch.stack((grid_x, grid_y), dim=-1).unsqueeze(0)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "print(\"Perspective Warp Function Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9806f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Prompts & Setup\n",
    "# View A: The actual flat image\n",
    "prompt_flat = \"A dark polished wood grain texture, top down view, high resolution\"\n",
    "\n",
    "# View B: The perspective illusion\n",
    "prompt_perspective = \"A carved wooden chess rook standing up, 3d render, photorealistic\"\n",
    "\n",
    "# Negative prompt\n",
    "negative_prompt = \"blurry, low quality, distortion, ugly, text, watermark, bad anatomy\"\n",
    "\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "print(f\"Flat Prompt: {prompt_flat}\")\n",
    "print(f\"Perspective Prompt: {prompt_perspective}\")\n",
    "\n",
    "# Labels\n",
    "label_flat = NegativeLabel(prompt_flat, negative_prompt)\n",
    "label_persp = NegativeLabel(prompt_perspective, negative_prompt)\n",
    "\n",
    "# Initialize Learnable Image (using Fourier features for better texture)\n",
    "learnable_image_maker = lambda: LearnableImageFourier(height=IMAGE_SIZE, width=IMAGE_SIZE, num_features=256, hidden_dim=256, scale=20).to(s.device)\n",
    "image_flat_param = learnable_image_maker()\n",
    "\n",
    "# Initialize Optimizer\n",
    "params = chain(image_flat_param.parameters())\n",
    "optim = torch.optim.SGD(params, lr=1e-4)\n",
    "\n",
    "# Generate Warp Grid\n",
    "# top : bot is about 3-1, which creates a strong perspective effect\n",
    "warp_grid = get_perspective_warp_grid(IMAGE_SIZE, IMAGE_SIZE, s.device, top_scale=1.0, bot_scale=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20516987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Main Optimization Loop\n",
    "\n",
    "NUM_ITER = 4000\n",
    "DISPLAY_INTERVAL = 200\n",
    "\n",
    "display_eta = rp.eta(NUM_ITER, title='Status: ')\n",
    "\n",
    "print('Starting training... Left: Flat Wood Texture (View A), Right: 3D Coke Can Illusion (View B)')\n",
    "\n",
    "try:\n",
    "    for iter_num in range(NUM_ITER):\n",
    "        display_eta(iter_num)\n",
    "\n",
    "        # 1. Get Base Image (View A)\n",
    "        flat_img = image_flat_param() # (C, H, W)\n",
    "        \n",
    "        # 2. Warp to Perspective View (View B)\n",
    "        perspective_img = F.grid_sample(flat_img.unsqueeze(0), warp_grid, align_corners=True, padding_mode='border').squeeze(0)\n",
    "\n",
    "        # 3. Compute Gradients/Loss\n",
    "        # Loss A: Flat image should look like Wood\n",
    "        s.train_step(\n",
    "            label_flat.embedding,\n",
    "            flat_img.unsqueeze(0),\n",
    "            noise_coef=0.1,\n",
    "            guidance_scale=50\n",
    "        )\n",
    "        \n",
    "        # Loss B: Perspective image should look like Coke Can\n",
    "        s.train_step(\n",
    "            label_persp.embedding,\n",
    "            perspective_img.unsqueeze(0),\n",
    "            noise_coef=0.1,\n",
    "            guidance_scale=80\n",
    "        )\n",
    "\n",
    "        # 4. Display Logic\n",
    "        with torch.no_grad():\n",
    "            if iter_num % DISPLAY_INTERVAL == 0:\n",
    "                from IPython.display import clear_output\n",
    "                clear_output(wait=True)\n",
    "\n",
    "                # Convert to numpy for display\n",
    "                disp_flat = rp.as_numpy_image(flat_img)\n",
    "                disp_persp = rp.as_numpy_image(perspective_img)\n",
    "\n",
    "                # Tile and Display\n",
    "                combined = rp.tiled_images([disp_flat, disp_persp])\n",
    "                rp.display_image(combined)\n",
    "                print(f\"Iteration: {iter_num}\")\n",
    "\n",
    "        # 5. Step\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped by user.')\n",
    "\n",
    "# Final Result will be shown again\n",
    "flat_img = image_flat_param()\n",
    "perspective_img = F.grid_sample(flat_img.unsqueeze(0), warp_grid, align_corners=True, padding_mode='border').squeeze(0)\n",
    "disp_flat = rp.as_numpy_image(flat_img)\n",
    "disp_persp = rp.as_numpy_image(perspective_img)\n",
    "\n",
    "print(\"Final Result:\")\n",
    "rp.display_image(rp.tiled_images([disp_flat, disp_persp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b2f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Save Images\n",
    "import cv2\n",
    "\n",
    "# Save the flat image\n",
    "file_name_flat = \"anamorphic_wood.png\"\n",
    "rp.save_image(disp_flat, file_name_flat)\n",
    "\n",
    "# Save the illusion view\n",
    "file_name_persp = \"anamorphic_chess.png\"\n",
    "rp.save_image(disp_persp, file_name_persp)\n",
    "\n",
    "print(f\"Saved to {file_name_flat} and {file_name_persp}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
