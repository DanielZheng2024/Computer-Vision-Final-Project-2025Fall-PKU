{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63896717",
   "metadata": {},
   "source": [
    "# 支持Image Prompt的Tangram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade -r requirements.txt\n",
    "%pip install rp --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4745bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境与依赖导入\n",
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import rp\n",
    "import source.stable_diffusion as sd\n",
    "from source.learnable_textures import LearnableImageFourier\n",
    "from source.stable_diffusion_labels import NegativeLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a63ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辅助：加载参考图像函数\n",
    "def load_ref_image(path, device):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"找不到图片文件: {os.path.abspath(path)}\")\n",
    "    img = rp.load_image(path)\n",
    "    img = rp.resize_image(img, (512, 512))\n",
    "    img_t = torch.from_numpy(img).permute(2, 0, 1).float().unsqueeze(0) / 255.0\n",
    "    return img_t.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备与模型初始化（可修改 model_name）\n",
    "gpu = rp.select_torch_device()\n",
    "model_name = \"runwayml/stable-diffusion-v1-5\"\n",
    "s = sd.StableDiffusion(gpu, model_name)\n",
    "device = s.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入参考图（若无可跳过）\n",
    "\n",
    "ref_image_a = load_ref_image(\"pictures/Original for Image Prompt/3.png\", device)\n",
    "ref_image_b = load_ref_image(\"pictures/Original for Image Prompt/2.png\", device)\n",
    "ref_image_coef_a = 0.1\n",
    "ref_image_coef_b = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bbec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提示词与训练超参\n",
    "prompt_a = \"a red fox, ultra detailed\"\n",
    "prompt_b = \"a blue robot, cinematic lighting\"\n",
    "negative_prompt = \"blurry, low quality\"\n",
    "\n",
    "SIZE = 256\n",
    "NUM_ITER = 6000  # 可在 notebook 中临时设小值以便测试\n",
    "DISPLAY_INTERVAL = 200\n",
    "\n",
    "label_a = NegativeLabel(prompt_a, negative_prompt)\n",
    "label_b = NegativeLabel(prompt_b, negative_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化可学习纹理（Fourier）和优化器\n",
    "prime = LearnableImageFourier(\n",
    "    height=SIZE, width=SIZE, hidden_dim=256, num_features=256, scale=10\n",
    ").to(device)\n",
    "\n",
    "# 使用 Adam，学习率可根据需要调整\n",
    "optim = torch.optim.Adam(prime.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc838fb",
   "metadata": {},
   "source": [
    "## 七巧板几何与掩码函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xy_grid(h, w, device):\n",
    "    ys = torch.linspace(-1, 1, h, device=device)\n",
    "    xs = torch.linspace(-1, 1, w, device=device)\n",
    "    y, x = torch.meshgrid(ys, xs, indexing='ij')\n",
    "    return x, y\n",
    "\n",
    "def triangle_mask(x, y, p0, p1, p2, sharpness=80.0):\n",
    "    pts = [p0, p1, p2]\n",
    "    m = torch.ones_like(x)\n",
    "    for i in range(3):\n",
    "        pi, pj, pk = pts[i], pts[(i+1)%3], pts[(i+2)%3]\n",
    "        ex, ey = (pj[0]-pi[0]), (pj[1]-pi[1])\n",
    "        a, b, c = -ey, ex, -( (-ey)*pi[0] + ex*pi[1] )\n",
    "        if a*pk[0] + b*pk[1] + c < 0: a, b, c = -a, -b, -c\n",
    "        m = m * torch.sigmoid(sharpness * (a*x + b*y + c))\n",
    "    return m\n",
    "\n",
    "def square_mask(x, y, cx=0.0, cy=0.0, s=0.25, sharpness=80.0):\n",
    "    return (torch.sigmoid(sharpness*(x-(cx-s))) * torch.sigmoid(sharpness*((cx+s)-x)) *\n",
    "            torch.sigmoid(sharpness*(y-(cy-s))) * torch.sigmoid(sharpness*((cy+s)-y)))\n",
    "\n",
    "def parallelogram_mask(x, y, cx=0.0, cy=0.0, w=0.55, h=0.22, shear=0.6, sharpness=80.0):\n",
    "    u = x - shear*y\n",
    "    return (torch.sigmoid(sharpness*(u-(cx-w/2))) * torch.sigmoid(sharpness*((cx+w/2)-u)) *\n",
    "            torch.sigmoid(sharpness*(y-(cy-h/2))) * torch.sigmoid(sharpness*((cy+h/2)-y)))\n",
    "\n",
    "x, y = make_xy_grid(SIZE, SIZE, device)\n",
    "T1 = triangle_mask(x, y, (-0.95, -0.95), (-0.15, -0.95), (-0.95, -0.15))\n",
    "T2 = triangle_mask(x, y, ( 0.15, -0.95), ( 0.95, -0.95), ( 0.95, -0.15))\n",
    "T3 = triangle_mask(x, y, (-0.95,  0.15), (-0.15,  0.15), (-0.95,  0.95))\n",
    "T4 = triangle_mask(x, y, ( 0.15,  0.15), ( 0.55,  0.15), ( 0.15,  0.55))\n",
    "T5 = triangle_mask(x, y, ( 0.60,  0.20), ( 0.95,  0.20), ( 0.95,  0.55))\n",
    "SQ = square_mask(x, y, cx=0.55, cy=0.75, s=0.18)\n",
    "PA = parallelogram_mask(x, y, cx=0.10, cy=0.75, w=0.55, h=0.22, shear=0.6)\n",
    "\n",
    "piece_masks = [T1, T2, T3, T4, T5, SQ, PA]\n",
    "mask_sum = torch.clamp(sum(piece_masks), min=1e-3)\n",
    "piece_masks = [m / mask_sum for m in piece_masks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b25750",
   "metadata": {},
   "source": [
    "## 视图变换与排布函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ee30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp(img_chw, tx, ty, rot_deg, scale, flip_x):\n",
    "    th = math.radians(rot_deg)\n",
    "    c, s_ = math.cos(th), math.sin(th)\n",
    "    sx = -scale if flip_x else scale\n",
    "    theta = torch.tensor([[[sx*c, -scale*s_, tx], [sx*s_, scale*c, ty]]], device=device)\n",
    "    grid = F.affine_grid(theta, size=(1, img_chw.shape[0], SIZE, SIZE), align_corners=False)\n",
    "    return F.grid_sample(img_chw.unsqueeze(0), grid, mode='bilinear', padding_mode='zeros', align_corners=False).squeeze(0)\n",
    "\n",
    "def tangram_view(prime_img, arr):\n",
    "    out = torch.zeros_like(prime_img)\n",
    "    for i, prm in enumerate(arr):\n",
    "        p = prime_img * piece_masks[i].unsqueeze(0)\n",
    "        out = out + warp(p, prm.get('tx',0), prm.get('ty',0), prm.get('rot_deg',0), prm.get('scale',1), prm.get('flip_x',False))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两种布局\n",
    "ARR_A = [dict(tx=-0.2, ty=-0.2, rot_deg=0, scale=1.0), dict(tx=0.2, ty=-0.2, rot_deg=90, scale=1.0), dict(tx=-0.2, ty=0.2, rot_deg=-90, scale=0.9), dict(tx=0.15, ty=0.15, rot_deg=0, scale=0.9), dict(tx=0.35, ty=0.35, rot_deg=180, scale=0.85), dict(tx=0.0, ty=0.35, rot_deg=45, scale=0.9), dict(tx=-0.05, ty=0.05, rot_deg=0, scale=0.95)]\n",
    "ARR_B = [dict(tx=-0.35, ty=-0.1, rot_deg=45, scale=1.0), dict(tx=0.1, ty=-0.35, rot_deg=135, scale=1.0), dict(tx=-0.05, ty=0.05, rot_deg=45, scale=0.95), dict(tx=0.25, ty=0.15, rot_deg=45, scale=0.9), dict(tx=0.35, ty=0.35, rot_deg=45, scale=0.85), dict(tx=0.05, ty=0.3, rot_deg=0, scale=0.95), dict(tx=-0.2, ty=0.25, rot_deg=45, scale=0.95, flip_x=True)]\n",
    "\n",
    "learnable_image_a = lambda: tangram_view(prime(), ARR_A)\n",
    "learnable_image_b = lambda: tangram_view(prime(), ARR_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c0e9a5",
   "metadata": {},
   "source": [
    "## 训练循环（SDS）\n",
    "运行前可在上方修改 NUM_ITER、DISPLAY_INTERVAL 等参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9b4b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = [label_a, label_b]\n",
    "weights = rp.as_numpy_array([1, 1])\n",
    "weights = weights / weights.sum() * len(weights)\n",
    "\n",
    "s.max_step, s.min_step = 990, 10\n",
    "ims = []\n",
    "\n",
    "def get_display_image():\n",
    "    with torch.no_grad():\n",
    "        view_a = rp.as_numpy_image(learnable_image_a().clamp(0, 1))\n",
    "        view_b = rp.as_numpy_image(learnable_image_b().clamp(0, 1))\n",
    "        p_base = rp.as_numpy_image(prime().clamp(0, 1))\n",
    "        return rp.tiled_images([view_a, view_b, p_base], length=3, border_thickness=0)\n",
    "\n",
    "television = rp.JupyterDisplayChannel(); television.display()\n",
    "display_eta = rp.eta(NUM_ITER, title='Tangram training')\n",
    "\n",
    "train_data = [\n",
    "    (label_a, learnable_image_a, weights[0], ref_image_a, ref_image_coef_a),\n",
    "    (label_b, learnable_image_b, weights[1], ref_image_b, ref_image_coef_b),\n",
    "]\n",
    "\n",
    "try:\n",
    "    for iter_num in range(NUM_ITER):\n",
    "        display_eta(iter_num)\n",
    "\n",
    "        for label, li, w, ref_img, ref_coef in rp.random_batch(train_data, batch_size=1):\n",
    "            _ = s.train_step(\n",
    "                text_embeddings = label.embedding,\n",
    "                pred_rgb = li()[None],\n",
    "                noise_coef = 0.1 * w,\n",
    "                guidance_scale = 80,\n",
    "                ref_image = ref_img,\n",
    "                ref_image_coef = ref_coef\n",
    "            )\n",
    "        \n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if not iter_num % DISPLAY_INTERVAL:\n",
    "                im = get_display_image()\n",
    "                ims.append(im)\n",
    "                television.update(im)\n",
    "                rp.display_image(get_display_image())\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted at', iter_num)\n",
    "    rp.display_image(get_display_image())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果函数\n",
    "def save_run(name):\n",
    "    folder = f\"untracked/tangram_image_prompt_runs/{name}_{int(time.time())}\"\n",
    "    rp.make_directory(folder)\n",
    "    ims_names = [f\"ims_{i:04d}.png\" for i in range(len(ims))]\n",
    "    with rp.SetCurrentDirectoryTemporarily(folder):\n",
    "        rp.save_images(ims, ims_names, show_progress=True)\n",
    "    print('Saved timelapse to:', folder)\n",
    "\n",
    "# save_run('tangram_a-b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
